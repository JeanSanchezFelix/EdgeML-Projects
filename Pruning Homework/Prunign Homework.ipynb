{"cells":[{"cell_type":"markdown","metadata":{"id":"K9B991I-h9A0"},"source":["# Edge ML Homework: Optimizing `MobileNetV2` with **Quantization** and **Pruning**\n","\n","## Pruning and Quantization of `MobileNetV2`\n","\n","This notebook demonstrates a complete workflow for optimizing a `MobileNetV2` model using quantization and pruning. The goal is to reduce the model's size and inference time while maintaining its performance on the ImageNet dataset.\n"]},{"cell_type":"markdown","metadata":{"id":"dRuZCJmicGVL"},"source":["## Instructions\n","- Using the notebook examples discussed in class and apply model pruning techniques to a `MobileNetv2` quantized model.\n","\n","- The objective is to perform pruning while preserving (as much as you can) original model accuracy.\n","\n","- The submission will be a Google Collab Notebook file.\n","\n","- Your notebook must perform the accuracy test of the original quantized model and the pruned model.\n","\n","- Runtime must use CPU (not GPU).\n","\n","- Accuracy will be based on on ImageNet Dataset Validation directory (This will be provided).\n","\n","- Image files must be stored on your google drive using the following code and data path:\n","\n","    ```py\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    data_path = \"/content/drive/My Drive/colab_files/imagenet/\"\n","    ```\n","\n","- Notebook must be documented using Jupyter Notebooks Markdown format.\n","\n","- On the documentation, explain how you did the pruning and why you decided on the current approach.\n","\n","## Approach used\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"trTiKo4OgJ0r"},"source":["---\n","### Load and Quantize the Model\n","\n","The selected `mobilenet_v2` model is initialized with a copy to serve as a baseline for comparison once the results of the pruned and quantized model have been obtained.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"Gm6dpbXdgJ0v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733542788443,"user_tz":240,"elapsed":542,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"}},"outputId":"fa935854-ce2f-42c8-f701-5879a91085d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model converted to quantized form.\n"]}],"source":["import torch\n","import torchvision\n","import torch.ao.quantization as quantization\n","import torch.nn.utils.prune as prune\n","import copy\n","\n","# Load the model with updated weights argument\n","original_model = torchvision.models.mobilenet_v2(weights=torchvision.models.MobileNet_V2_Weights.IMAGENET1K_V1)\n","reduced_model = copy.deepcopy(original_model)\n","\n","quantized_model = torch.ao.quantization.quantize_dynamic(\n","    reduced_model,\n","    {torch.nn.Linear},\n","    dtype=torch.qint8)\n","\n","print(\"Model converted to quantized form.\")"]},{"cell_type":"markdown","metadata":{"id":"hxiIBbjk4Pwe"},"source":["---\n","### Evaluation Funtion\n","\n","**Purpose**: The `evaluate` function measures a model's performance on a validation dataset by calculating loss, accuracy, and inference time. It also provides real-time feedback by printing progress every 10 batches.\n","\n"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"nRfQPwb54Pwf","executionInfo":{"status":"ok","timestamp":1733542788444,"user_tz":240,"elapsed":13,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"}}},"outputs":[],"source":["import time\n","import numpy as np\n","\n","def evaluate(model, data_loader, loss_history):\n","    model.eval()\n","\n","    total_samples = len(data_loader.dataset)\n","    correct_samples = 0\n","    total_loss = 0\n","    times = []\n","\n","    with torch.no_grad():\n","        for i, (data, target) in enumerate(data_loader):\n","            start_time = time.time()\n","            output = torch.nn.functional.log_softmax(model(data), dim=1)\n","            end_time = time.time()\n","            times.append(1000 * (end_time - start_time))\n","            loss = torch.nn.functional.nll_loss(output, target, reduction='sum')\n","            _, pred = torch.max(output, dim=1)\n","            total_loss += loss.item()\n","            correct_samples += pred.eq(target).sum()\n","\n","            # Print progress every 10 batches\n","            if (i + 1) % 10 == 0:\n","                print(f\"Processed {i + 1} batches out of {len(data_loader)}\")\n","\n","    avg_inference = np.mean(times)\n","    std_dev_inference = np.std(times)\n","    min_inference = np.min(times)\n","    max_inference = np.max(times)\n","\n","    avg_loss = total_loss / total_samples\n","    loss_history.append(avg_loss)\n","    print('\\tAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n","          '\\tAccuracy: ' + '{:5}'.format(correct_samples) + '/' +\n","          '{:5}'.format(total_samples) + ' (' +\n","          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)' +\n","          '\\tAverage inference time: ' + '{:.4f}ms'.format(avg_inference) + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"3EQkjsz-4Pwg"},"source":["---\n","### Load the ImageNet Dataset\n","**Purpose**: Initialize all the necessary image preprocessing for the Validation Set like resizing, cropping, normalization, and conversion to tensors for efficient model evaluation. The Validation Set from ImageNet is loaded onto the notebook to reduce processing time during pruning and fine-tuning.\n"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5492,"status":"ok","timestamp":1733542793925,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"},"user_tz":240},"id":"N2JCGiuf4Pwh","outputId":"8e535312-1fad-43a9-d199-695da310be16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from google.colab import drive\n","from torch.utils.data import Subset\n","drive.mount('/content/drive')\n","\n","data_path = \"/content/drive/My Drive/ColabNotebooks/imagenet\"\n","imagenet_val = datasets.ImageNet(\n","\troot=data_path,\n","\tsplit='val',\n","    transform=transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(\n","            mean=[0.485, 0.456, 0.406],\n","            std=[0.229, 0.224, 0.225])\n","\t])\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"KeMihwaW4Pwj"},"source":["---\n","## Data Loader for Model\n","\n","**Purpose**: Creates three `Subsets` with random samples from a given seed for further evaluation.\n","\n","- **460** samples for training and validation (split **60%-40%**)\n","- **150** samples for testing.\n","\n","Three `DataLoaders` are then initialized:\n","\n","  - **Training DataLoader (`data_loader_train`)**\n","  - **Validation DataLoader (`data_loader_val`)**\n","  - **Testing DataLoader (`data_loader_test`)**\n","\n"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1733542794152,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"},"user_tz":240},"id":"nciSkOim4Pwk","outputId":"8762b82a-fdc8-4a6f-eae9-af88c4e46ce6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training DataLoader created with 276 samples.\n","Validation DataLoader created with 184 samples.\n","Testing DataLoader created with 150 samples.\n"]}],"source":["from torch.utils.data import Subset\n","import torch\n","\n","max_sample_train = 460\n","max_sample_test = 150\n","\n","# Random seeds to avoid overlap\n","all_indexes = torch.randperm(len(imagenet_val), generator=torch.Generator().manual_seed(99)).tolist()\n","\n","train_indexes = all_indexes[:int(max_sample_train * 0.6)]  # 60% of training samples for training\n","val_indexes = all_indexes[int(max_sample_train * 0.6):max_sample_train]  # 40% of training samples for validation\n","\n","# Test indexes are non-overlapping\n","test_indexes = [idx for idx in all_indexes if idx not in train_indexes and idx not in val_indexes][:max_sample_test]\n","\n","dataset_train_subset = Subset(imagenet_val, train_indexes)\n","dataset_val_subset = Subset(imagenet_val, val_indexes)\n","dataset_test_subset = Subset(imagenet_val, test_indexes)\n","\n","# DataLoaders\n","data_loader_train = torch.utils.data.DataLoader(\n","    dataset_train_subset,\n","    batch_size=2,\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","data_loader_val = torch.utils.data.DataLoader(\n","    dataset_val_subset,\n","    batch_size=20,\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","data_loader_test = torch.utils.data.DataLoader(\n","    dataset_test_subset,\n","    batch_size=25,\n","    shuffle=True,\n","    num_workers=2\n",")\n","\n","# Print DataLoader stats\n","print(f\"Training DataLoader created with {len(data_loader_train.dataset)} samples.\")\n","print(f\"Validation DataLoader created with {len(data_loader_val.dataset)} samples.\")\n","print(f\"Testing DataLoader created with {len(data_loader_test.dataset)} samples.\")\n"]},{"cell_type":"markdown","metadata":{"id":"Rg_hOIrppUAY"},"source":["---\n","### Iterative Pruning Function\n","\n","**Purpose**: Dynamically prune the model using an iteration to find the optimal sparsity threshold while monitoring accuracy. Applies `L1-norm-based unstructured pruning` to the weight of the convolutional layer. It removes a fraction of weights (amount is determined by the current sparsity level) based on their magnitudes.\n","\n","**Why?:** In my case, structured pruning could have made it more challenging to observe the accuracy drop reaching its threshold. This format was not suitable for structured pruning as it involves erasing entire layers, increasing unpredictability. Random pruning was too inconsistent."]},{"cell_type":"code","execution_count":54,"metadata":{"id":"RPJwN8UEpkxc","executionInfo":{"status":"ok","timestamp":1733542794153,"user_tz":240,"elapsed":13,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"}}},"outputs":[],"source":["import torch\n","import torch.nn.utils.prune as prune\n","import copy\n","\n","def iterative_pruning(model, data_loader, step, max_sparsity):\n","    pruned_model = copy.deepcopy(model)\n","    sparsity_levels = []\n","\n","    print(\"\\n--- Iterative Pruning ---\\n\")\n","    for sparsity in torch.arange(step, max_sparsity + step, step):\n","        for name, module in pruned_model.named_modules():\n","            if isinstance(module, torch.nn.Conv2d):\n","                prune.l1_unstructured(module, name=\"weight\", amount=sparsity.item())\n","                prune.remove(module, \"weight\")\n","        sparsity_levels.append(sparsity.item())\n","\n","        # Evaluate pruned model\n","        loss = []\n","        print(f\"\\n--- Sparsity Level: {sparsity.item() * 100:.0f}% ---\\n\")\n","        evaluate(pruned_model, data_loader, loss)\n","\n","    return pruned_model, sparsity_levels"]},{"cell_type":"markdown","metadata":{"id":"oublW20cpnp_"},"source":["---\n","### Fine-Tuning Function\n","\n","**Purpose**: Failed attempt to implement`Post-Training Pruning` to recover accuracy by training the pruned model. Since then, I have also tried to apply `Quantization Aware Training` `(QAT)`, but after training, the evaluation function does not work because a specific backend function does not support that type of quantized model.\n","\n","I will leave the funtion here for future testing.\n",""]},{"cell_type":"code","execution_count":55,"metadata":{"id":"J9491EwMpsOl","executionInfo":{"status":"ok","timestamp":1733542794154,"user_tz":240,"elapsed":13,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"}}},"outputs":[],"source":["import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","from torch.nn.utils import clip_grad_norm_\n","\n","def fine_tune_model(model, train_loader, val_loader, epochs, lr, loss_history=None):\n","    if loss_history is None:\n","        loss_history = []\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_loss = 0\n","\n","        # Iterate through the training data\n","        for data, target in train_loader:\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n","        print(f\"Learning Rate after epoch {epoch + 1}: {optimizer.param_groups[0]['lr']:.6f}\")\n","        loss_history.append(total_loss)\n","        print(f\"Validation Metrics After Epoch {epoch + 1}:\")\n","        evaluate(model, val_loader, loss_history)\n"]},{"cell_type":"markdown","metadata":{"id":"jqQPdoIPrGdA"},"source":["---\n","### Pruning Size Comparison\n","\n","**Purpose**: Evaluates the storage efficiency of pruning by comparing the sizes of the model before and after applying pruning. It performs iterative pruning of the quantized model, progressively increasing the sparsity levels, and tracks the size of the original model and the pruned model in `megabytes` `(MB)`. In this case I have seen that a good threshold for prunnign this model is a `15%` sparsity, without having major drops in accuracy.\n","\n","**Note:** Despite implementing the `prune.remove(module, \"weight\")` function to eliminate weights with value 0, the model size (MB) remains unchanged."]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31154,"status":"ok","timestamp":1733542825297,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"},"user_tz":240},"id":"h3ZezMj3Ksb8","outputId":"d2edd609-7423-400e-882f-9bb8759f05ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Iterative Pruning ---\n","\n","\n","--- Sparsity Level: 5% ---\n","\n","Processed 10 batches out of 10\n","\tAverage test loss: 0.8737\tAccuracy:   147/  184 (79.89%)\tAverage inference time: 899.2363ms\n","\n","\n","--- Sparsity Level: 10% ---\n","\n","Processed 10 batches out of 10\n","\tAverage test loss: 0.9582\tAccuracy:   143/  184 (77.72%)\tAverage inference time: 984.3173ms\n","\n","\n","--- Sparsity Level: 15% ---\n","\n","Processed 10 batches out of 10\n","\tAverage test loss: 1.1911\tAccuracy:   131/  184 (71.20%)\tAverage inference time: 838.4227ms\n","\n","Original Model Size: 3.34 MB\n","Pruned Model Size: 2.12 MB\n"]}],"source":["loss_history = []\n","\n","pruned_model = copy.deepcopy(quantized_model)\n","\n","pruned_model, sparsity_levels = iterative_pruning(\n","    pruned_model, data_loader_val, step=0.05, max_sparsity=0.1\n",")\n","\n","original_size = sum(p.numel() for p in original_model.parameters())\n","pruned_size = sum(p.numel() for p in pruned_model.parameters())\n","print(f\"Original Model Size: {original_size / (1024 ** 2):.2f} MB\")\n","print(f\"Pruned Model Size: {pruned_size / (1024 ** 2):.2f} MB\")"]},{"cell_type":"markdown","source":["---\n","### Fine-tuning Activation\n","\n","**Purpose**: Failed Fine-tuning, that was suposed to adjusts the weights of the pruned model using a new training dataset and a specified number of epochs, allowing the model to adapt to the new data and improve its performance... at least in theory."],"metadata":{"id":"QUSLpj_tJgIT"}},{"cell_type":"code","source":["loss_history = []\n","\n","tuned_model = copy.deepcopy(pruned_model)\n","\n","fine_tune_model(\n","    tuned_model,\n","    data_loader_train,\n","    data_loader_val,\n","    epochs=5,\n","    lr=1e-3,\n","    loss_history=loss_history\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SIqyJDC2I62","executionInfo":{"status":"ok","timestamp":1733542993186,"user_tz":240,"elapsed":167903,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"}},"outputId":"bd1c713c-0c1a-407a-8cd9-2f50638fbb1f"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5, Loss: 606.7614\n","Learning Rate after epoch 1: 0.001000\n","Validation Metrics After Epoch 1:\n","Processed 10 batches out of 10\n","\tAverage test loss: 1.3007\tAccuracy:   125/  184 (67.93%)\tAverage inference time: 878.2687ms\n","\n","Epoch 2/5, Loss: 618.6003\n","Learning Rate after epoch 2: 0.001000\n","Validation Metrics After Epoch 2:\n","Processed 10 batches out of 10\n","\tAverage test loss: 1.1599\tAccuracy:   129/  184 (70.11%)\tAverage inference time: 870.9489ms\n","\n","Epoch 3/5, Loss: 591.8172\n","Learning Rate after epoch 3: 0.001000\n","Validation Metrics After Epoch 3:\n","Processed 10 batches out of 10\n","\tAverage test loss: 1.1663\tAccuracy:   135/  184 (73.37%)\tAverage inference time: 762.3266ms\n","\n","Epoch 4/5, Loss: 594.2369\n","Learning Rate after epoch 4: 0.001000\n","Validation Metrics After Epoch 4:\n","Processed 10 batches out of 10\n","\tAverage test loss: 1.1700\tAccuracy:   132/  184 (71.74%)\tAverage inference time: 867.8891ms\n","\n","Epoch 5/5, Loss: 607.5869\n","Learning Rate after epoch 5: 0.001000\n","Validation Metrics After Epoch 5:\n","Processed 10 batches out of 10\n","\tAverage test loss: 1.2702\tAccuracy:   127/  184 (69.02%)\tAverage inference time: 921.5311ms\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"ih6gT0JqraJ9"},"source":["\n","---\n","### Final Evaluation of the Quantizied,  Pruned and Fine-Tuned models\n","\n","**Purpose**: This script performs the final evaluation of the quantized, pruned, and fine-tuned models on the test dataset. Additionally, it compares the sizes of the original, quantized, pruned, and fine-tuned models to assess the impact of quantization and pruning on model storage (MB)"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"c2S-loHnnPzy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733543018284,"user_tz":240,"elapsed":25116,"user":{"displayName":"JEANPIERE I SANCHEZ-FELIX","userId":"17732696205576824611"}},"outputId":"35334d41-30a7-42e6-a3ce-18b882c52bcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Quantized Model File Size: 9.94 MB\n","\n","--- Final Metrics for the Quantized Model---\n","\n","\tAverage test loss: 1.1679\tAccuracy:   105/  150 (70.00%)\tAverage inference time: 1202.4129ms\n","\n","\n","--- Final Metrics for Quantized & Pruned Model ---\n","\n","\tAverage test loss: 1.3917\tAccuracy:   104/  150 (69.33%)\tAverage inference time: 1106.6957ms\n","\n","\n","--- Final Metrics for Quantized, Pruned Model & Fine-Tuned Model ---\n","\n","\tAverage test loss: 1.5561\tAccuracy:    96/  150 (64.00%)\tAverage inference time: 1168.1273ms\n","\n","Original Model Size: 3.34 MB\n","Quantized Model Size: 2.12 MB\n","Pruned Model Size: 2.12 MB\n","Tuned Model Size: 2.12 MB\n"]}],"source":["import os\n","\n","torch.save(quantized_model.state_dict(), \"quantized_model.pth\")\n","model_size = os.path.getsize(\"quantized_model.pth\") / (1024 ** 2)\n","print(f\"Quantized Model File Size: {model_size:.2f} MB\")\n","\n","# Final evaluation of pruned and fine-tuned model\n","print(\"\\n--- Final Metrics for the Quantized Model---\\n\")\n","evaluate(quantized_model, data_loader_test, loss_history)\n","print(\"\\n--- Final Metrics for Quantized & Pruned Model ---\\n\")\n","evaluate(pruned_model, data_loader_test, loss_history)\n","print(\"\\n--- Final Metrics for Quantized, Pruned Model & Fine-Tuned Model ---\\n\")\n","evaluate(tuned_model, data_loader_test, loss_history)\n","\n","\n","# Compare model sizes\n","original_size = sum(p.numel() for p in original_model.parameters())\n","quantized_size = sum(p.numel() for p in quantized_model.parameters())\n","pruned_size = sum(p.numel() for p in pruned_model.parameters())\n","tuned_size = sum(p.numel() for p in tuned_model.parameters())\n","\n","print(f\"Original Model Size: {original_size / (1024 ** 2):.2f} MB\")\n","print(f\"Quantized Model Size: {quantized_size / (1024 ** 2):.2f} MB\")\n","print(f\"Pruned Model Size: {pruned_size / (1024 ** 2):.2f} MB\")\n","print(f\"Tuned Model Size: {tuned_size / (1024 ** 2):.2f} MB\")\n","\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1S4MD1SClHCsLMDWiMpS6IM4lznT5kLJD","timestamp":1733431103118}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}